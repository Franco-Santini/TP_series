---
format: 
  pdf:
    fig-pos: "H"
    fig-cap-location: top
    tbl-cap-location: top
lang: es
echo: FALSE
message: FALSE
warning: FALSE
geometry:
  - top= 25mm
  - left= 20mm
  - right = 20mm
  - bottom = 25mm
  - heightrounded
header-includes:
  - \usepackage{ragged2e}
  - \usepackage{hyperref}
  - \usepackage{float}
  - \floatplacement{table}{H}
---

::: {.center data-latex=""}

\vspace{3cm}

```{r logo facultad, echo=F, include = T, out.width= "60%"}
knitr::include_graphics("logounr.png")
```

\pagenumbering{gobble}

\vspace{5cm}

\Large
**LICENCIATURA EN ESTADÍSTICA**

\vspace{1cm}

\Large
**Trabajo Práctico**


\vspace{0.3cm}
\large

*"Evaluación de las Tendencias de Ventas Mensuales en una Empresa de Logística*

\vspace{0.1cm}

*Mediante Series de Tiempo"*

\vspace{8cm}

\large

**Autor: Santini, Franco**

**Docentes: Mendez, Fernanda - Sigal, Facundo**

**2024**
\normalsize
\newpage
\hypersetup{linkcolor = black}
\tableofcontents


\newpage
\pagenumbering{arabic}

:::

\newpage

```{r librerias}
library(fpp3) # Paquete del libro fpp3
library(dplyr) # Manejo de datos
library(forecast) # Pronosticos
library(lubridate) # Manejo de fechas
library(ggplot2) # Gráficos
library(MASS) # Transformación Box-Cox
library(readxl) # Leer archivos excel
library(kableExtra) # Tablas
library(ggrepel) # Texto en el gráfico estacional
```

# Introducción

En este trabajo se busca estudiar las unidades vendidas (bebidas con y sin alcohol) en Hectolitro^[Unidad de volúmen equivalente a 100 litros.] (HL) de una importante empresa de logística en la ciudad de Casilda, Santa Fe. El estudio se realiza con 80 observaciones, medidas mensualmente en el período (01/01/2018 - 31/08/2024).



Cabe aclarar que en el período de estudio, atravesamos un evento muy catastrófico en todas las áreas, particularmente en el sector de logística, la pandemia del COVID-19. Al afectar principalmente a las personas, Argentina implementó el Aislamiento Social, Preventivo y Obligatorio (ASPO) como medida para combatir la pandemia de COVID-19. Debido a esta medida, a fines de marzo del 2020 - principios de abril del 2020, el sector de logística fue afectado y en general se produjo una caída en las ventas con respecto al año anterior.
 
Teniendo esto en cuenta, resulta de interés pronosticar a futuro las unidades vendidas en (HL) de la empresa, mediante modelos de *series de tiempo*.

## Análisis descriptivo

En primera instancia, comenzamos con el gráfico de la serie para observar el comportamiento de las ventas a través del período en estudio.

```{r carga datos 2}
datos2 <- read_excel("Datos/empresa_casilda.xlsx")
datos_trabajo_2 <- datos2

datos_trabajo_2$`Año/Mes` <- ym(datos_trabajo_2$`Año/Mes`) # Pasamos a formato fecha
datos_trabajo_2$Año <- factor(datos_trabajo_2$Año)
```

```{r datos empresa 1}
datos_empresa_1 <- datos_trabajo_2 |> 
  group_by(`Año/Mes`, Distribuidora) |> 
  filter(Distribuidora == "EMPRESA 1") |> # Me quedo solo con los datos de la empresa 1
  filter(`Año/Mes` != "2024-09-01") |> # Filtro septiembre porque esta incompleto
  summarise(
    Cantidad_total_HL = sum(`Cantidad Total en HL`)
  ) |> 
  ungroup()
```

```{r grafico serie 2}
#| fig-cap: "Unidades vendidas mensuales en (HL)"
#| label: fig-serie1

datos_empresa_1 |> 
  ggplot() +
  aes(x = `Año/Mes`, y = Cantidad_total_HL) +
  geom_line() +
  geom_point(size = 1.5, color = "dodgerblue2") +
  scale_y_continuous(breaks = seq(6000, 20000, 2000)) +
  scale_x_date(breaks = scales::date_breaks("1 year"), labels = scales::date_format("%Y")) +
  labs(x = "Fecha", y = "Cantidad total vendida (HL)") +
  theme_bw()
```

En la @fig-serie1 se puede observar un comportamiento estacional de las unidades vendidas, disminuye considerablemente en los meses (mayo, junio y julio) y luego aumenta considerablemente en los meses (noviembre - diciembre - enero) en casi todos los años, exceptuando el año 2020 que puede deberse a la pandemia.

```{r grafico estacional 2}
#| fig-cap: "Comportamiento anual de las unidades vendidas en (HL)"
#| label: fig-serie2

etiqueta_graph <- unique(year(datos_empresa_1$`Año/Mes`))

datos_empresa_1 |> 
  mutate(anio = factor(year(`Año/Mes`)),
         mes = factor(month(`Año/Mes`))) |> 
  ggplot() +
  aes(x = mes, y = Cantidad_total_HL, group = anio, color = anio) +
  geom_line() +
  geom_text_repel(data = subset(datos_empresa_1 |> 
  mutate(anio = factor(year(`Año/Mes`)),
         mes = factor(month(`Año/Mes`))), mes == 1),
    aes(color = anio, label = anio),
    fontface = "bold",
    size = 2.5,
    # direction = "y",
    segment.size = 0,
    segment.alpha = 0,
    nudge_x = -0.25,
    box.padding = 0,
    force = 0.4
  ) +
  scale_y_continuous(breaks = seq(6000, 20000, 2000)) +
  labs(x = "Mes", y = "Cantidad total vendida (HL)", color = "Año") +
  theme_bw() +
  theme(
    legend.position = "none"
  )
```
La @fig-serie2 podemos observar que claramente hay un comportamiento estacional de las unidades vendidas, pero se descarta cualquier tipo de tendencia creciente o decreciente de las mismas, dado que no se observa ni un crecimiento, ni un decrecimiento año a año de las unidades vendidas mensuales. 

```{r grafico autocorrelacion 1}
autocorrelacion_2 <- acf(datos_empresa_1$Cantidad_total_HL, lag.max = 80, plot = F)
datos_autocorrelacion <- data.frame(
  acf = autocorrelacion_2$acf,
  lag = autocorrelacion_2$lag
)

alpha <- 0.95
conf.lims <- c(-1,1)*qnorm((1 + alpha)/2)/sqrt(autocorrelacion_2$n.used)
```

```{r grafico de autocorrelacion parcial 1}
pautocorrelacion_2 <- pacf(datos_empresa_1$Cantidad_total_HL, lag.max = 80, plot = F)
datos_pautocorrelacion <- data.frame(
  pacf = pautocorrelacion_2$acf,
  lag = pautocorrelacion_2$lag
)

alpha <- 0.95
conf.lims2 <- c(-1,1)*qnorm((1 + alpha)/2)/sqrt(pautocorrelacion_2$n.used)
```


```{r graficos fac y facp}
#| label: fig-serie3
#| layout-ncol: 2
#| fig-cap: "Funciones de autocorrelación muestral"
#| fig-subcap:
#|   - "FACM"
#|   - "FACPM"

datos_autocorrelacion |> 
  ggplot() +
  aes(x = lag, y = acf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = acf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(x = "Rezago", y = expression(rho[k])) +
  theme_bw()

datos_pautocorrelacion |> 
  ggplot() +
  aes(x = lag, y = pacf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = pacf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims2, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(y = expression(Phi[kk]), x = "Rezago") +
  theme_bw()
```

De acuerdo con lo mostrado en @fig-serie3, se puede observar que la FACM tiene un decrecimiento lento y sinuoso, notando también que en los rezagos 12, 24, 36 y 48 son significativos esto da un indicio de que la serie tiene un comportamiento estacional, mientras que la FACPM no parece tener un patrón claro.

### Analisis de dispersion

```{r boxplot por año 2}
#| fig-cap: "Boxplots de las unidades vendidas en (HL) por año"
#| label: fig-serie4

datos_empresa_1 |> 
  mutate(anio = factor(year(`Año/Mes`))) |> 
  filter(anio != 2024) |> # Filtro el 2024 porque está incompleto
  ggplot() +
  aes(x = anio, y = Cantidad_total_HL) +
  geom_boxplot(fill = "dodgerblue2") +
  scale_y_continuous(breaks = seq(6000, 20000, 2000)) +
  labs(x = "Año", y = "Cantidad total vendida (HL)") +
  theme_bw()


```

Se puede observar en la @fig-serie4 que la variabilidad no parece ser constante año a año, por lo que puede estar dando una advertencia de que la serie no es estacionaria en variancia, además se puede apreciar la presencia de outliers en los años 2018, 2019, 2021 y 2022. Se excluyó el año 2024 de la @fig-serie4 porque no estaban los datos completos. 

Una vez observados los Boxplots, procederemos a realizar la transformación de Box-Cox. Dependiendo del valor de $\lambda$ obtenido, determinaremos si es necesario transformar la serie o si puede mantenerse en su forma original. Además, puede ser de utilidad ajusta el coeficiente de variación según los valores de $\lambda$ arrojados por la transformación de Box-Cox, de esta manera, podremos identificar si una transformación de potencia es adecuada para estabilizar la varianza de la serie. Aquel valor de $\lambda$ para el cuál se minimice el coeficiente de variación, será la transformación que tendremos que realizar.

```{r transformacion box-cox}
bc_transf <- boxcox(lm(data = datos_empresa_1, Cantidad_total_HL ~ 1), plotit = F)

# Grafico de la transformacion box cox
# data.frame(
#   x = bc_transf$x,
#   y = bc_transf$y
# ) |> 
#   ggplot() +
#   aes(x = x, y = y) +
#   geom_line() +
#   geom_segment(x = bc_transf$x[which.max(bc_transf$y)], xend = bc_transf$x[which.max(bc_transf$y)], y = -76, yend = bc_transf$y[bc_transf$x == bc_transf$x[which.max(bc_transf$y)]], lty = 2) +
#   scale_x_continuous(breaks = seq(-2, 2, 0.5)) +
#   labs(x = expression(lambda), y = "Log-verosimilitud") +
#   theme_bw()
```

```{r transformacion box-cox 2}
# data.frame(
#   lambda = bc_transf$x,
#   y = bc_transf$y
# ) |> 
#   filter(lambda %in% c(-2, -1, -0.5, 0, 0.5, 1, 2))
# Con esto solo aplicamos las transformaciones 
# lambda = 2 implica y^2
# lambda = 1 implica y (no se transforma)
# lambda = 0.5 implica sqrt(y)
# lambda = 0 implica ln(y)
# lambda = -0.5 implica 1/sqrt(y)
# lambda = -1 implica 1/y
# lambda = -2 implica 1/y^2

y_lambda2 <- datos_empresa_1$Cantidad_total_HL^2
y_lambda05 <- sqrt(datos_empresa_1$Cantidad_total_HL)
y_lambda0 <- log(datos_empresa_1$Cantidad_total_HL)
y_lambda.05 <- 1/sqrt(datos_empresa_1$Cantidad_total_HL)
y_lambda.1 <- 1/datos_empresa_1$Cantidad_total_HL
y_lambda.2 <- 1/(datos_empresa_1$Cantidad_total_HL^2)

bc <- data.frame(
  lambda = c(-2, -1, -0.5, 0, 0.5, 1, 2),
  Coeficiente_de_variacion = c(sd(y_lambda.2)/mean(y_lambda.2), sd(y_lambda.1)/mean(y_lambda.1), sd(y_lambda.05)/mean(y_lambda.05), sd(y_lambda0)/mean(y_lambda0), sd(y_lambda05)/mean(y_lambda05), sd(datos_empresa_1$Cantidad_total_HL)/mean(datos_empresa_1$Cantidad_total_HL), sd(y_lambda2)/mean(y_lambda2))
  )
```


```{r transformacion box-cox 3}
#| tbl-cap: "Coeficiente de variación"

bc |> 
  `colnames<-`(c("$\\lambda$", "Coeficiente de variación")) |> 
  kable(digits = 4,
        format = "pipe")
```

\newpage

Observando la Tabla 1, el coeficiente de variación mínimo esta asociado a un $\lambda = 0$, por lo que es apropiado aplicar la transformacion $y^{(\lambda)} = ln(y)$. 

## Identificación del modelo

```{r datos transformados}
datos_empresa_transformados <- datos_empresa_1 |> 
  mutate(ln_y = log(datos_empresa_1$Cantidad_total_HL),
         anio = factor(year(`Año/Mes`)),
         mes = factor(month(`Año/Mes`)))
```

```{r grafico de la fac serie transformada}
autocorrelacion_transf <- acf(datos_empresa_transformados$ln_y, lag.max = 80, plot = F)
datos_autocorrelacion_transf <- data.frame(
  acf = autocorrelacion_transf$acf,
  lag = autocorrelacion_transf$lag
)

alpha <- 0.95
conf.lims <- c(-1,1)*qnorm((1 + alpha)/2)/sqrt(autocorrelacion_transf$n.used)
```

```{r grafico de la facp serie transformada}
pautocorrelacion_trans <- pacf(datos_empresa_transformados$ln_y, lag.max = 80, plot = F)
datos_pautocorrelacion_trans <- data.frame(
  pacf = pautocorrelacion_trans$acf,
  lag = pautocorrelacion_trans$lag
)

alpha <- 0.95
conf.lims2 <- c(-1,1)*qnorm((1 + alpha)/2)/sqrt(pautocorrelacion_trans$n.used)
```

```{r descriptivo serie transformada}
#| label: fig-serie5
#| layout: [[49, -2 ,49], [49, -2 ,49]]
#| fig-cap: "Resúmen de la Serie transformada"
#| fig-subcap: 
#|   - "Log. natural de las unidades vendidas mensuales en (HL)"
#|   - "Boxplots del Log. natural de las unidades vendidas en (HL) por año"
#|   - "FACM"
#|   - "FACPM"

datos_empresa_transformados |> 
  ggplot() +
  aes(x = `Año/Mes`, y = ln_y) +
  geom_line() +
  geom_point(size = 1.5, color = "dodgerblue2") +
  scale_y_continuous(breaks = seq(8, 10, 0.2)) +
  scale_x_date(breaks = scales::date_breaks("1 year"), labels = scales::date_format("%Y")) +
  labs(x = "Fecha", y = "Log. natural de la cantidad total vendida (HL)") +
  theme_bw()

datos_empresa_transformados |> 
  filter(anio != 2024) |>
  ggplot() +
  aes(x = anio, y = ln_y) +
  geom_boxplot(fill = "dodgerblue2") +
  scale_y_continuous(breaks = seq(8, 10, 0.2)) +
  labs(x = "Año", y = "Log. natural de la cantidad total vendida (HL)") +
  theme_bw()

datos_autocorrelacion_transf |> 
  ggplot() +
  aes(x = lag, y = acf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = acf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(x = "Rezago", y = expression(rho[k])) +
  theme_bw()

datos_pautocorrelacion_trans |> 
  ggplot() +
  aes(x = lag, y = pacf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = pacf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims2, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(y = expression(Phi[kk]), x = "Rezago") +
  theme_bw()
```

Luego de transformar a la serie, se realizó la @fig-serie5 que contiene un resúmen acerca del comportamiento de la serie. Notando, que ahora en el gráfico (b) se puede observar que la variabilidad parece ser un poco más constante año a año.

```{r tendencia de la serie transformada, eval=FALSE}
tabla_promedios <- datos_empresa_transformados |>
  group_by(anio) |>
  summarise(media_anio = mean(ln_y)) |>
  ungroup()

media_gral <- datos_empresa_transformados |>
  filter(anio != 2024) |>
  summarise(media = mean(ln_y))

tabla_promedios |>
  filter(anio != 2024) |>
  ggplot() +
  geom_line(aes(x = anio, y = media_anio, group = 1)) +
  geom_point(aes(x = anio, y = media_anio)) +
  geom_hline(yintercept = media_gral$media, lty = 2) +
  labs(x = "Año", y = "Promedio del log. natural de la cantidad total vendida (HL)") +
  theme_bw()
```

```{r datos entrenamiento y prueba}
datos_entrenamiento <- datos_empresa_transformados[1:74,]
datos_prueba <- datos_empresa_transformados[75:80,]
```

### Diferenciación de la serie

Una vez realizado el análisis descriptivo, se notó el comportamiento estacional de la serie, por lo qué, se realiza una diferenciación en la parte estacional de la misma, dado que lo rezagos estacionales en la FACM observada en la @fig-serie5 parecen decrecer lentamente de forma lineal, pasando a trabajar con 62 observaciones. 

```{r diferenciacion de la serie}
diferencia_est <- difference(datos_entrenamiento$ln_y, differences = 12)
datos_diferencia <- datos_entrenamiento
datos_diferencia$dif_est <- diferencia_est
```

```{r fac dif est}
autocorrelacion_dif <- acf(datos_diferencia$dif_est[13:74], lag.max = 61, plot = F)
datos_autocorrelacion_dif <- data.frame(
  acf = autocorrelacion_dif$acf,
  lag = autocorrelacion_dif$lag
)

alpha <- 0.95
conf.lims <- c(-1,1)*qnorm((1 + alpha)/2)/sqrt(autocorrelacion_dif$n.used)
```

```{r facp dif est}
pautocorrelacion_dif <- pacf(datos_diferencia$dif_est[13:74], lag.max = 61, plot = F)
datos_pautocorrelacion_dif <- data.frame(
  pacf = pautocorrelacion_dif$acf,
  lag = pautocorrelacion_dif$lag
)

alpha <- 0.95
conf.lims <- c(-1,1)*qnorm((1 + alpha)/2)/sqrt(pautocorrelacion_dif$n.used)
```

\newpage

```{r graficos de la serie diferenciada}
#| label: fig-serie6
#| layout: [[50], [50, 50]]
#| fig-cap: "Resúmen de la Serie diferenciada en la parte estacional"
#| fig-subcap: 
#|   - "Log. natural de las unidades vendidas mensuales en (HL)"
#|   - "FACM"
#|   - "FACPM"

datos_diferencia[13:74,] |>  
  ggplot() +
  aes(x = `Año/Mes`, y = dif_est) +
  geom_line() +
  geom_point(size = 1.5, color = "dodgerblue2") +
  scale_x_date(breaks = scales::date_breaks("1 year"), labels = scales::date_format("%Y")) +
  labs(x = "Fecha", y = "Log. natural de la cantidad total vendida (HL)") +
  theme_bw()

datos_autocorrelacion_dif |> 
  ggplot() +
  aes(x = lag, y = acf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = acf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(x = "Rezago", y = expression(rho[k])) +
  theme_bw()

datos_pautocorrelacion_dif |> 
  ggplot() +
  aes(x = lag, y = pacf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = pacf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(x = "Rezago", y = expression(Phi[kk])) +
  theme_bw()
```

En la @fig-serie6 se observa, el gráfico de la serie diferenciada en la parte estacional y sus respectivas funciones de autocorrelación muestral y de autocorrelación parcial muestral. En el gráfico (a) se puede observar que la serie parece ser estacionaria, dado que varia de manera oscilante sobre un valor constante. 
Luego para realizar la identificación de los posibles modelos que se pueden ajustar a esta serie, utilizaremos los gráficos (b) y (c). En el gráfico de la FACM se puede observar que 2 rezagos son significativos, y el tercer rezago está en el límite de ser significativo, viendo la parte estacional parece que los rezagos 12, 24 y 36 son significativos, persentando un decrecimiento exponencial. En el gráfico de la FACPM se puede observar que solo los primeros 2 rezagos son significativos, y el rezago 12 correspondiente a la parte estacional, parece estar al límite de ser significativo.

\newpage

Por lo que teniendo esto en cuenta, planteamos los siguientes modelos que se pueden ajustar a nuestra serie: 

- Modelo 1: $SARIMA(0,0,3)(1,1,0)_{12}$
- Modelo 2: $SARIMA(0,0,2)(1,1,0)_{12}$
- Modelo 3: $SARIMA(2,0,0)(1,1,0)_{12}$


```{r tsibble}
datos_diferencia_2 <- datos_diferencia |> 
  mutate(mes = as.numeric(mes),
         date = yearmonth(`Año/Mes`),
         key = 1) |> 
  dplyr::select(-`Año/Mes`) |> 
  as_tsibble(key = key,
             index = date,
             validate = T,
             regular = T)
```

Una vez planteado los modelos que vamos a utilizar para el pronóstico de la serie, se procede a estimarlos y compararlos.

```{r ajustes de modelo con la variable transformada}
#| tbl-cap: "Comparación de los modelos"

ajustes2 <- datos_diferencia_2 |>
  model(
    auto = ARIMA(log(Cantidad_total_HL), stepwise = F, approximation = F, method = "ML"),
    sarima003110 = ARIMA(log(Cantidad_total_HL) ~ pdq(0,0,3) + PDQ(1,1,0), method = "ML"),
    sarima002110 = ARIMA(log(Cantidad_total_HL) ~ pdq(0,0,2) + PDQ(1,1,0), method = "ML"),
    sarima200110 = ARIMA(log(Cantidad_total_HL) ~ pdq(2,0,0) + PDQ(1,1,0), method = "ML"),
    sarima100110 = ARIMA(log(Cantidad_total_HL) ~ pdq(1,0,0) + PDQ(1,1,0), method = "ML")
  )
# ajustes2 |>
#   dplyr::select(-key) |>
#   tidyr::pivot_longer(everything(), names_to = "Modelos",
#                      values_to = "Orden")
glance(ajustes2 |> dplyr::select(-key, -'sarima100110')) |> 
  arrange(AICc) |> 
  dplyr::select(.model:BIC) |>
  mutate(nombre_modelos = c("$SARIMA(1,0,0)(0,1,1)_{12}$", "$SARIMA(2,0,0)(1,1,0)_{12}$", "$SARIMA(0,0,2)(1,1,0)_{12}$", "$SARIMA(0,0,3)(1,1,0)_{12}$")) |>
  relocate(nombre_modelos) |> 
  dplyr::select(-.model) |> 
  `colnames<-`(c("Modelos", "$\\hat\\sigma^2$", "Log_veros.","AIC", "AICc", "BIC")) |> 
  kable(digits = 4)
```

```{r estimacion con arima}
m_auto_2 <- arima(datos_diferencia_2$ln_y, order = c(1,0,0), seasonal = list(order = c(0,1,1), period = 12), method = "ML")


# m_auto_2 # Los dos parámetros son significativos

m_prop_2 <- arima(datos_diferencia_2$ln_y, order = c(2,0,0), seasonal = list(order = c(1,1,0), period = 12), method = "ML")

# m_prop_2 # ar1 y sar1 son significativos, ar2 no es significativo

m_prop_2.1 <- arima(datos_diferencia_2$ln_y, order = c(1,0,0), seasonal = list(order = c(1,1,0), period = 12), method = "ML")
```

Se puede observar, que los modelos con menor $AIC$ son:

1. $SARIMA(2,0,0)(1,1,0)_{12}$
2. $SARIMA(1,0,0)(0,1,1)_{12}$

El modelo 1 tiene 3 parámetros de los cuáles $\phi_2$ no es significativo, por lo que a dicho modelo le sacamos un parámetro en la parte regular. Por lo que el cambiamos el modelo 1 por un modelo $SARIMA(1,0,0)(1,1,0)_{12}$. Con respecto al modelo 2, sus dos parámetros son significativos, teniendo además una estimación de $\hat\sigma^2$ menor que la del modelo 1. De igual manera, seguiré con los modelos, definiendo cuál usaré para la predicción, aquél que tenga una mejor capacidad predictiva, teniendo en cuenta la verificación de los supuestos de los mismos.

## Evaluación de los supuestos de los modelos

Esta instancia se centra en la verificación de los supuestos de ambos modelos mencionados anteriormente. Se hará un análisis exhaustivo para el modelo $SARIMA(1,0,0)(0,1,1)_{12}$, mientras que para el modelo $SARIMA(1,0,0)(1,1,0)_{12}$, al ser un procedimiento análogo, se dejarán en el anexo la @fig-serie-anexo.

```{r chequeo de los supuestos}
m_propuesto <- augment(ajustes2) |>
  filter(.model == "sarima100110")

m_auto <- augment(ajustes2) |>
  filter(.model == "auto")
```

```{r data frame para los graficos}
acf_auto <- acf(m_auto$.innov, lag.max = 61, plot = F)
pacf_auto <- pacf(m_auto$.innov, lag.max = 61, plot = F)

datos_autocorrelacion_auto <- data.frame(
  lag = acf_auto$lag,
  acf = acf_auto$acf
)

datos_pautocorrelacion_auto <- data.frame(
  lag = pacf_auto$lag,
  pacf = pacf_auto$acf
)
```

\newpage 

```{r residuos auto graficos}
#| label: fig-serie7
#| layout: [[49, -2 ,49], [49, -2 ,49]]
#| fig-cap: "Análisis de residuos $SARIMA(1,0,0)(0,1,1)_{12}$"
#| fig-subcap: 
#|   - "Residuos estandarizados vs fecha"
#|   - "Histograma de los residuos estandarizados"
#|   - "FACM de los residuos"
#|   - "FACPM de los residuos"

m_auto |> 
  mutate(innov_est = .innov/sd(.innov)) |> 
  ggplot() +
  aes(x = datos_diferencia$`Año/Mes`, y = innov_est) +
  geom_line() +
  geom_hline(yintercept = c(-3, 3), linetype = "dashed", col = "blue") +
  geom_point(size = 1.5, color = "dodgerblue2") +
  scale_x_date(breaks = scales::date_breaks("1 year"), labels = scales::date_format("%Y")) +
  labs(x = "Fecha", y = "Residuos estandarizados") +
  theme_bw() # Hay un outlier

m_auto |> 
  mutate(innov_est = .innov/sd(.innov)) |> 
  ggplot() +
  aes(x = innov_est) +
  geom_histogram(aes(x = innov_est, y = ..density..), fill = "dodgerblue2", color = "black", bins = 12) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), size = 1) +
  labs(x = "Residuos estandarizados", y = "Densidad") +
  theme_bw()

datos_autocorrelacion_auto |>
  filter(lag != 0) |> 
  ggplot() +
  aes(x = lag, y = acf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = acf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(x = "Rezago", y = expression(rho[k])) +
  theme_bw()

datos_pautocorrelacion_auto |> 
  ggplot() +
  aes(x = lag, y = pacf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = pacf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(x = "Rezago", y = expression(Phi[kk])) +
  theme_bw()

```

En la @fig-serie7 se puede observar en los gráficos (a) y (b) que hay una observación atípica, correspondiente al año 2020, lo cuál se puede deber a alguna situación inusual ocurrida en pandemia, además los residuos varían alrededor del cero y parecen tener una variancia constante. También se puede apreciar, en el gráfico (b) que los residuos parecen ser normales, obviamente sin incluir al outlier. Luego en los gráficos (c) y (d), da la impresión de que los residuos son incorrelados, en la tabla 4 que se encuentra en el anexo, se incluye el test de Ljung-Box para comprobar que los residuos son incorrelados. Por lo que podemos concluir que el modelo $SARIMA(1,0,0)(0,1,1)_{12}$ cumple con los supuestos.

Para el modelo $SARIMA(1,0,0)(1,1,0)_{12}$ se realizó lo mismo obteniendo resultados análogos al modelo anterior, se puede observar en la @fig-serie-anexo.

## Evaluación de la capacidad predictiva

Dado que los dos modelos mencionados anteriormente satisfacen los supuestos teóricos, la manera de decidir cuál utilizar para realizar las predicciones es en base a la capacidad predictiva que tienen, es decir, nos quedaremos con aquél modelo que tenga menor error de predicción. Para ello haremos uso de varias métricas, haciendo especial énfasis sobre el *MAPE*, dado que es expresado como un porcentaje lo cuál facilita las interpretaciones y las comparaciones.


```{r comparación de la capacidad predictiva 1}
#| tbl-cap: "Evaluación de la capacidad predictiva"

# Convertimos el data set a objeto series de tiempo
datos_prueba_2 <- datos_prueba |> 
  mutate(mes = as.numeric(mes),
         date = yearmonth(`Año/Mes`),
         key = 1) |> 
  dplyr::select(-`Año/Mes`) |> 
  as_tsibble(key = key,
             index = date,
             validate = T,
             regular = T)

# Comparación de la capacidada predictiva
forecast(ajustes2, h=6) |>
  filter(.model %in% c('auto', 'sarima100110')) |>
  accuracy(datos_prueba_2) |>
  dplyr::select(.model, RMSE:MAPE, -MPE) |> 
  mutate(nombre_modelos = c("$SARIMA(1,0,0)(0,1,1)_{12}$", "$SARIMA(1,0,0)(1,1,0)_{12}$")) |>
  relocate(nombre_modelos) |> 
  dplyr::select(-.model) |> 
  `colnames<-`(c("Modelos", "RMSE", "MAE", "MAPE")) |> 
  kable(digits = 4)
```

En la tabla 3, se puede verificar que el modelo $SARIMA(1,0,0)(0,1,1)_{12}$ tiene todas las medidas de error de pronóstico más bajas, por lo cuál, dicho modelo se utilizará para realizar las predicciones.

```{r data frame con los datos de la predicción}
# Predicciones
predicciones <- forecast(ajustes2, h=6) |>
  filter(.model == 'auto')

# Data frame con las predicciones
datos_prueba_2 <- datos_prueba_2 |> 
  mutate(estimacion_puntual = predicciones$.mean,
         distribucion = predicciones$Cantidad_total_HL)
```

```{r gráfico de las predicciones con el modelo auto}
#| label: fig-serie8
#| layout-nrow: 2
#| fig-cap: "Comparación del pronóstico vs el valor real"
#| fig-subcap:
#|   - "Pronósticos de las unidades vendidas en (HL) desde 03/2024 - 08/2024"
#|   - "Pronósticos de las unidades vendidas en (HL) desde 03/2024 - 08/2024 vs unidades vendidas en (HL) reales"
#| fig-height: 2.80
#| fig-width: 4

predicciones |> 
  autoplot(datos_diferencia_2 |> 
             mutate(date = yearmonth(date)),
           size = 1, colour = "dodgerblue2") +
  scale_y_continuous(breaks = seq(6000, 20000, 2000)) +
  guides(fill_ramp = guide_legend(title = "Intervalo de predicción")) +
  labs(x = "Fecha", 
       y = "Cantidad total vendida (HL)") +
  theme_bw() +
  theme(legend.position = "bottom")


predicciones |> 
  autoplot(datos_prueba_2, colour = "dodgerblue2", size = 1) +
  scale_y_continuous(breaks = seq(6000, 20000, 1000)) +
  guides(fill_ramp = guide_legend(title = "Intervalo de predicción")) +
  labs(x = "Fecha", 
       y = "Cantidad total vendida (HL)") +
  theme_bw() +
  theme(legend.position = "bottom")
```

\newpage

En la @fig-serie8 se pueden observar las predicciones realizadas utilizando el modelo seleccionado anteriormente, en el gráfico (b) se puede ver una comparación entre el valor real (línea negra) y las predicciones realizadas (línea azul), observando que los valores reales en su mayoría se encuentran dentro del intervalo de predicción. Lo que sucede en agosto es que la empresa a la que se le analizaron los datos tuvo una decaída en las ventas sujeto a un problema en las bonificaciones por falta de presupuesto.


## Conclusión

El análisis de las ventas mensuales reveló un comportamiento estacional sin tendencias a través de los años, el cuál no tiene mayores inconvenientes además de que la variancia no es constante en el tiempo y el outlier encontrado en el año 2020, sujeto al escenario atípico que se vivió en dicho año. En base a esto se ajusto un modelo SARIMA no muy complicado, con una diferencia en la parte estacional, una parte autorregresiva de primer órden en la parte regular y una parte promedio móvil de primer orden en la parte estacional, el cuál satisface todos los supuestos teóricos.

Luego, en la parte de los resultados se vió que el modelo ajustado tenía un *MAPE* del 14.4% aproximadamente, lo cuál significa que el error promedio de los pronósticos se desvían un 14.4% respecto a las unidades vendidas reales, lo cuál es aceptable pero lo ideal sería un error más chico. 
Por último, tener en cuenta el pronóstico de agosto del año 2024, dado que en dicho mes hubo un problema con las bonificaciones en la empresa por falta de presupuesto, lo cuál esto puede modificar el desempeño del modelo y tal vez el error obtenido sería inferior a lo que se obtuvo.


\newpage

## Anexo

Todo el código con el cuál se desarrollo el trabajo práctico se encuentra en mi repostiorio de Github, al cuál se puede acceder haciendo [click aquí](https://github.com/Franco-Santini/TP_series).

```{r data frame para los graficos 2}
acf_prop <- acf(m_propuesto$.innov, lag.max = 61, plot = F)
pacf_prop <- pacf(m_propuesto$.innov, lag.max = 61, plot = F)

datos_autocorrelacion_prop <- data.frame(
  lag = acf_prop$lag,
  acf = acf_prop$acf
)

datos_pautocorrelacion_prop <- data.frame(
  lag = pacf_prop$lag,
  pacf = pacf_prop$acf
)
```

```{r ljung-box test 1}
# Tabla cada 6 rezagos
ljung_box_auto <- data.frame(
  rezago = c(6, 12, 18, 24, 30, 36),
  test = c(ljung_box(m_auto$.innov, lag = 6, dof = 2)[2],
           ljung_box(m_auto$.innov, lag = 12, dof = 2)[2],
           ljung_box(m_auto$.innov, lag = 18, dof = 2)[2],
           ljung_box(m_auto$.innov, lag = 24, dof = 2)[2],
           ljung_box(m_auto$.innov, lag = 30, dof = 2)[2],
           ljung_box(m_auto$.innov, lag = 36, dof = 2)[2])
)

ljung_box_prop <- data.frame(
  rezago = c(6, 12, 18, 24, 30, 36),
  test = c(ljung_box(m_propuesto$.innov, lag = 6, dof = 2)[2],
           ljung_box(m_propuesto$.innov, lag = 12, dof = 2)[2],
           ljung_box(m_propuesto$.innov, lag = 18, dof = 2)[2],
           ljung_box(m_propuesto$.innov, lag = 24, dof = 2)[2],
           ljung_box(m_propuesto$.innov, lag = 30, dof = 2)[2],
           ljung_box(m_propuesto$.innov, lag = 36, dof = 2)[2])
)
```

```{r test ljung-box 1}
#| tbl-cap: "Test de Ljung-Box cada 6 rezagos"
#| tbl-subcap: 
#|   - "Modelo $SARIMA(1,0,0)(0,1,1)_{12}$"
#|   - "Modelo $SARIMA(1,0,0)(1,1,0)_{12}$"
#| layout-ncol: 2

ljung_box_auto |> 
    `colnames<-`(c("Rezago", "P-value")) |> 
    kable(digits = 4)

ljung_box_prop |> 
    `colnames<-`(c("Rezago", "P-value")) |> 
    kable(digits = 4)
```


```{r residuos auto graficos 2}
#| label: fig-serie-anexo
#| layout: [[49, -2 ,49], [49, -2 ,49]]
#| fig-cap: "Análisis de residuos $SARIMA(1,0,0)(1,1,0)_{12}$"
#| fig-subcap: 
#|   - "Residuos estandarizados vs fecha"
#|   - "Histograma de los residuos estandarizados"
#|   - "FACM de los residuos"
#|   - "FACPM de los residuos"

m_propuesto |> 
  mutate(innov_est = .innov/sd(.innov)) |> 
  ggplot() +
  aes(x = datos_diferencia$`Año/Mes`, y = innov_est) +
  geom_line() +
  geom_hline(yintercept = c(-3, 3), linetype = "dashed", col = "blue") +
  geom_point(size = 1.5, color = "dodgerblue2") +
  scale_x_date(breaks = scales::date_breaks("1 year"), labels = scales::date_format("%Y")) +
  labs(x = "Fecha", y = "Residuos estandarizados") +
  theme_bw() # Hay un outlier

m_propuesto |> 
  mutate(innov_est = .innov/sd(.innov)) |> 
  ggplot() +
  aes(x = innov_est) +
  geom_histogram(aes(x = innov_est, y = ..density..), fill = "dodgerblue2", color = "black", bins = 12) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), size = 1) +
  labs(x = "Residuos estandarizados", y = "Densidad") +
  theme_bw()

datos_autocorrelacion_prop |>
  filter(lag != 0) |> 
  ggplot() +
  aes(x = lag, y = acf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = acf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(x = "Rezago", y = expression(rho[k])) +
  theme_bw()

datos_pautocorrelacion_prop |> 
  ggplot() +
  aes(x = lag, y = pacf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = pacf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(x = "Rezago", y = expression(Phi[kk])) +
  theme_bw()

```



\newpage

## Bibliografía

- Wei, W.S. (2006). Time Series Analysis: Univariate and Multivariate Methods, 2nd edition

- Hyndman, R.J., & Athanasopoulos, G. (2021). Forecasting: principles and practice, 3rd edition

- Guerrero, V.M. (1993). Time series analysis supported by power transformation
