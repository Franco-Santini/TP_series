---
format: 
  pdf:
    fig-pos: "H"
    fig-cap-location: top
    tbl-cap-location: top
lang: es
echo: FALSE
message: FALSE
warning: FALSE
geometry:
  - top= 25mm
  - left= 20mm
  - right = 20mm
  - bottom = 25mm
  - heightrounded
header-includes:
  - \usepackage{ragged2e}
  - \usepackage{hyperref}
  - \usepackage{float}
  - \floatplacement{table}{H}
---

::: {.center data-latex=""}

\vspace{3cm}

```{r logo facultad, echo=F, include = T, out.width= "60%"}
knitr::include_graphics("logounr.png")
```

\pagenumbering{gobble}

\vspace{5cm}

\Large
**LICENCIATURA EN ESTADÍSTICA**

\vspace{1cm}

\Large
**Trabajo Práctico**


\vspace{0.3cm}
\large

*"Evaluación de las Tendencias de Ventas Mensuales en una Empresa de Logística*

\vspace{0.1cm}

*Mediante Series de Tiempo"*

\vspace{8cm}

\large

**Autor: Santini, Franco**

**Docentes: Mendez, Fernanda - Sigal, Facundo**

**2024**
\normalsize
\newpage
\hypersetup{linkcolor = black}
\tableofcontents


\newpage
\pagenumbering{arabic}

:::

\newpage

```{r librerias}
library(fpp3) # Paquete del libro fpp3
library(dplyr) # Manejo de datos
library(forecast) # Pronosticos
library(lubridate) # Manejo de fechas
library(ggplot2) # Gráficos
library(MASS) # Transformación Box-Cox
library(readxl) # Leer archivos excel
library(kableExtra) # Tablas
library(ggrepel) # Texto en el gráfico estacional
```

# Introducción

En este trabajo se busca estudiar las unidades vendidas (bebidas con y sin alcohol) en hectolitros^[Unidad de volúmen equivalente a 100 litros.] (HL) de una importante empresa de logística en la ciudad de Casilda, Santa Fe. El estudio incluye 80 observaciones, medidas mensualmente durante el período comprendido entre el 1 de enero de 2018 y el 31 de agosto de 2024.

Es importante señalar que, durante el período de estudio, se atravesó un evento catastrófico que afectó a diversas áreas, particularmente al sector logístico: la pandemia de COVID-19. Ante el impacto en la población, Argentina implementó el Aislamiento Social, Preventivo y Obligatorio (ASPO) como medida para combatir la pandemia. Esta disposición, vigente desde fines de marzo - principios de abril de 2020, afectó significativamente al sector logístico, lo que resultó en una caída generalizada de las ventas en comparación con el año anterior.
 
Considerando estos antecedentes, resulta de interés pronosticar las unidades vendidas en hectolitros (HL) de la empresa para períodos futuros, utilizando modelos de *series de tiempo*.

## Análisis descriptivo

En primera instancia, se presenta el gráfico de la serie temporal para analizar el comportamiento de las ventas a lo largo del período de estudio.

```{r carga datos 2}
datos2 <- read_excel("Datos/empresa_casilda.xlsx")
datos_trabajo_2 <- datos2

datos_trabajo_2$`Año/Mes` <- ym(datos_trabajo_2$`Año/Mes`) # Pasamos a formato fecha
datos_trabajo_2$Año <- factor(datos_trabajo_2$Año)
```

```{r datos empresa 1}
datos_empresa_1 <- datos_trabajo_2 |> 
  group_by(`Año/Mes`, Distribuidora) |> 
  filter(Distribuidora == "EMPRESA 1") |> # Me quedo solo con los datos de la empresa 1
  filter(`Año/Mes` != "2024-09-01") |> # Filtro septiembre porque esta incompleto
  summarise(
    Cantidad_total_HL = sum(`Cantidad Total en HL`)
  ) |> 
  ungroup()
```

```{r grafico serie 2}
#| fig-cap: "Unidades vendidas mensuales en (HL)"
#| label: fig-serie1

datos_empresa_1 |> 
  ggplot() +
  aes(x = `Año/Mes`, y = Cantidad_total_HL) +
  geom_line() +
  geom_point(size = 1.5, color = "dodgerblue2") +
  scale_y_continuous(breaks = seq(6000, 20000, 2000)) +
  scale_x_date(breaks = scales::date_breaks("1 year"), labels = scales::date_format("%Y")) +
  labs(x = "Fecha", y = "Cantidad total vendida (HL)") +
  theme_bw()
```

En la @fig-serie1 se puede observar un comportamiento estacional de las unidades vendidas, disminuye considerablemente en los meses (mayo, junio y julio) y luego aumenta considerablemente en los meses (noviembre - diciembre - enero) en casi todos los años, exceptuando el año 2020 que puede deberse a la pandemia.

```{r grafico estacional 2}
#| fig-cap: "Comportamiento anual de las unidades vendidas en (HL)"
#| label: fig-serie2

etiqueta_graph <- unique(year(datos_empresa_1$`Año/Mes`))

datos_empresa_1 |> 
  mutate(anio = factor(year(`Año/Mes`)),
         mes = factor(month(`Año/Mes`))) |> 
  ggplot() +
  aes(x = mes, y = Cantidad_total_HL, group = anio, color = anio) +
  geom_line() +
  geom_text_repel(data = subset(datos_empresa_1 |> 
  mutate(anio = factor(year(`Año/Mes`)),
         mes = factor(month(`Año/Mes`))), mes == 1),
    aes(color = anio, label = anio),
    fontface = "bold",
    size = 2.5,
    # direction = "y",
    segment.size = 0,
    segment.alpha = 0,
    nudge_x = -0.25,
    box.padding = 0,
    force = 0.4
  ) +
  scale_y_continuous(breaks = seq(6000, 20000, 2000)) +
  labs(x = "Mes", y = "Cantidad total vendida (HL)", color = "Año") +
  theme_bw() +
  theme(
    legend.position = "none"
  )
```
Se puede interpretar en la @fig-serie2 que claramente hay un comportamiento estacional de las unidades vendidas, pero se descarta cualquier tipo de tendencia creciente o decreciente de las mismas, dado que no se observa ni un crecimiento, ni un decrecimiento año a año de las unidades vendidas mensuales. 

```{r grafico autocorrelacion 1}
autocorrelacion_2 <- acf(datos_empresa_1$Cantidad_total_HL, lag.max = 80, plot = F)
datos_autocorrelacion <- data.frame(
  acf = autocorrelacion_2$acf,
  lag = autocorrelacion_2$lag
)

alpha <- 0.95
conf.lims <- c(-1,1)*qnorm((1 + alpha)/2)/sqrt(autocorrelacion_2$n.used)
```

```{r grafico de autocorrelacion parcial 1}
pautocorrelacion_2 <- pacf(datos_empresa_1$Cantidad_total_HL, lag.max = 80, plot = F)
datos_pautocorrelacion <- data.frame(
  pacf = pautocorrelacion_2$acf,
  lag = pautocorrelacion_2$lag
)

alpha <- 0.95
conf.lims2 <- c(-1,1)*qnorm((1 + alpha)/2)/sqrt(pautocorrelacion_2$n.used)
```


```{r graficos fac y facp}
#| label: fig-serie3
#| layout-ncol: 2
#| fig-cap: "Funciones de autocorrelación muestral"
#| fig-subcap:
#|   - "FACM"
#|   - "FACPM"

datos_autocorrelacion |> 
  ggplot() +
  aes(x = lag, y = acf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = acf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(x = "Rezago", y = expression(rho[k])) +
  theme_bw()

datos_pautocorrelacion |> 
  ggplot() +
  aes(x = lag, y = pacf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = pacf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims2, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(y = expression(Phi[kk]), x = "Rezago") +
  theme_bw()
```

De acuerdo con lo mostrado en la @fig-serie3, se puede observar que la FACM tiene un decrecimiento lento y sinusoidal, notando también que en los rezagos 12, 24, 36 y 48 son significativos esto da un indicio de que la serie tiene un comportamiento estacional, mientras que la FACPM no parece tener un patrón claro.

### Análisis de dispersión

```{r boxplot por año 2}
#| fig-cap: "Boxplots de las unidades vendidas en (HL) por año"
#| label: fig-serie4

datos_empresa_1 |> 
  mutate(anio = factor(year(`Año/Mes`))) |> 
  filter(anio != 2024) |> # Filtro el 2024 porque está incompleto
  ggplot() +
  aes(x = anio, y = Cantidad_total_HL) +
  geom_boxplot(fill = "dodgerblue2") +
  scale_y_continuous(breaks = seq(6000, 20000, 2000)) +
  labs(x = "Año", y = "Cantidad total vendida (HL)") +
  theme_bw()


```

El análisis de la @fig-serie4 revela que la variabilidad no parece ser constante año a año, por lo que puede estar dando una advertencia de que la serie no es estacionaria en variancia, además se puede apreciar algunas observaciones alejadas del resto en los años 2018, 2019, 2021 y 2022. Se excluyó el año 2024 de la @fig-serie4 porque no estaban los datos completos. 

Una vez observados los Boxplots, se procede a realizar la transformación de Box-Cox. Dependiendo del valor de $\lambda$ obtenido, se determina si es necesario transformar la serie o si puede mantenerse en su forma original. Además, es de utilidad calcular el coeficiente de variación según los valores de $\lambda$ arrojados por la transformación de Box-Cox, de esta manera, se podrá identificar si una transformación de potencia es adecuada para estabilizar la variancia de la serie. Aquel valor de $\lambda$ para el cuál se minimice el coeficiente de variación, será la transformación que tendremos que realizar.

```{r transformacion box-cox}
bc_transf <- boxcox(lm(data = datos_empresa_1, Cantidad_total_HL ~ 1), plotit = F)

# Grafico de la transformacion box cox
# data.frame(
#   x = bc_transf$x,
#   y = bc_transf$y
# ) |> 
#   ggplot() +
#   aes(x = x, y = y) +
#   geom_line() +
#   geom_segment(x = bc_transf$x[which.max(bc_transf$y)], xend = bc_transf$x[which.max(bc_transf$y)], y = -76, yend = bc_transf$y[bc_transf$x == bc_transf$x[which.max(bc_transf$y)]], lty = 2) +
#   scale_x_continuous(breaks = seq(-2, 2, 0.5)) +
#   labs(x = expression(lambda), y = "Log-verosimilitud") +
#   theme_bw()
```

```{r transformacion box-cox 2}
# data.frame(
#   lambda = bc_transf$x,
#   y = bc_transf$y
# ) |> 
#   filter(lambda %in% c(-2, -1, -0.5, 0, 0.5, 1, 2))
# Con esto solo aplicamos las transformaciones 
# lambda = 2 implica y^2
# lambda = 1 implica y (no se transforma)
# lambda = 0.5 implica sqrt(y)
# lambda = 0 implica ln(y)
# lambda = -0.5 implica 1/sqrt(y)
# lambda = -1 implica 1/y
# lambda = -2 implica 1/y^2

y_lambda2 <- datos_empresa_1$Cantidad_total_HL^2
y_lambda05 <- sqrt(datos_empresa_1$Cantidad_total_HL)
y_lambda0 <- log(datos_empresa_1$Cantidad_total_HL)
y_lambda.05 <- 1/sqrt(datos_empresa_1$Cantidad_total_HL)
y_lambda.1 <- 1/datos_empresa_1$Cantidad_total_HL
y_lambda.2 <- 1/(datos_empresa_1$Cantidad_total_HL^2)

bc <- data.frame(
  lambda = c(-2, -1, -0.5, 0, 0.5, 1, 2),
  Coeficiente_de_variacion = c(sd(y_lambda.2)/mean(y_lambda.2), sd(y_lambda.1)/mean(y_lambda.1), sd(y_lambda.05)/mean(y_lambda.05), sd(y_lambda0)/mean(y_lambda0), sd(y_lambda05)/mean(y_lambda05), sd(datos_empresa_1$Cantidad_total_HL)/mean(datos_empresa_1$Cantidad_total_HL), sd(y_lambda2)/mean(y_lambda2))
  )
```


```{r transformacion box-cox 3}
#| tbl-cap: "Coeficiente de variación"

bc |> 
  `colnames<-`(c("$\\lambda$", "Coeficiente de variación")) |> 
  kable(digits = 4,
        format = "pipe")
```

\newpage

Se observa en la Tabla 1 que el coeficiente de variación mínimo esta asociado a un $\lambda = 0$, por lo que es apropiado aplicar la transformación $y^{(\lambda)} = ln(y)$. 

## Identificación de modelos

```{r datos transformados}
datos_empresa_transformados <- datos_empresa_1 |> 
  mutate(ln_y = log(datos_empresa_1$Cantidad_total_HL),
         anio = factor(year(`Año/Mes`)),
         mes = factor(month(`Año/Mes`)))
```

```{r grafico de la fac serie transformada}
autocorrelacion_transf <- acf(datos_empresa_transformados$ln_y, lag.max = 80, plot = F)
datos_autocorrelacion_transf <- data.frame(
  acf = autocorrelacion_transf$acf,
  lag = autocorrelacion_transf$lag
)

alpha <- 0.95
conf.lims <- c(-1,1)*qnorm((1 + alpha)/2)/sqrt(autocorrelacion_transf$n.used)
```

```{r grafico de la facp serie transformada}
pautocorrelacion_trans <- pacf(datos_empresa_transformados$ln_y, lag.max = 80, plot = F)
datos_pautocorrelacion_trans <- data.frame(
  pacf = pautocorrelacion_trans$acf,
  lag = pautocorrelacion_trans$lag
)

alpha <- 0.95
conf.lims2 <- c(-1,1)*qnorm((1 + alpha)/2)/sqrt(pautocorrelacion_trans$n.used)
```

```{r descriptivo serie transformada}
#| label: fig-serie5
#| layout: [[49, -2 ,49], [49, -2 ,49]]
#| fig-cap: "Resumen de la Serie transformada"
#| fig-subcap: 
#|   - "Log. natural de las unidades vendidas mensuales en (HL)"
#|   - "Boxplots del Log. natural de las unidades vendidas en (HL) por año"
#|   - "FACM"
#|   - "FACPM"

datos_empresa_transformados |> 
  ggplot() +
  aes(x = `Año/Mes`, y = ln_y) +
  geom_line() +
  geom_point(size = 1.5, color = "dodgerblue2") +
  scale_y_continuous(breaks = seq(8, 10, 0.2)) +
  scale_x_date(breaks = scales::date_breaks("1 year"), labels = scales::date_format("%Y")) +
  labs(x = "Fecha", y = "Log. natural de la cantidad total vendida (HL)") +
  theme_bw()

datos_empresa_transformados |> 
  filter(anio != 2024) |>
  ggplot() +
  aes(x = anio, y = ln_y) +
  geom_boxplot(fill = "dodgerblue2") +
  scale_y_continuous(breaks = seq(8, 10, 0.2)) +
  labs(x = "Año", y = "Log. natural de la cantidad total vendida (HL)") +
  theme_bw()

datos_autocorrelacion_transf |> 
  ggplot() +
  aes(x = lag, y = acf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = acf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(x = "Rezago", y = expression(rho[k])) +
  theme_bw()

datos_pautocorrelacion_trans |> 
  ggplot() +
  aes(x = lag, y = pacf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = pacf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims2, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(y = expression(Phi[kk]), x = "Rezago") +
  theme_bw()
```

Luego de transformar a la serie, se realizó la @fig-serie5 que contiene un resumen acerca del comportamiento de la serie. Notando, que ahora en la Figura (5b) se puede observar que la variabilidad parece ser un poco más constante año a año.

```{r tendencia de la serie transformada, eval=FALSE}
tabla_promedios <- datos_empresa_transformados |>
  group_by(anio) |>
  summarise(media_anio = mean(ln_y)) |>
  ungroup()

media_gral <- datos_empresa_transformados |>
  filter(anio != 2024) |>
  summarise(media = mean(ln_y))

tabla_promedios |>
  filter(anio != 2024) |>
  ggplot() +
  geom_line(aes(x = anio, y = media_anio, group = 1)) +
  geom_point(aes(x = anio, y = media_anio)) +
  geom_hline(yintercept = media_gral$media, lty = 2) +
  labs(x = "Año", y = "Promedio del log. natural de la cantidad total vendida (HL)") +
  theme_bw()
```

```{r datos entrenamiento y prueba}
datos_entrenamiento <- datos_empresa_transformados[1:74,]
datos_prueba <- datos_empresa_transformados[75:80,]
```

### Diferenciación de la serie

Una vez realizado el análisis descriptivo, se notó el comportamiento estacional de la serie, por lo qué, se realiza una diferenciación en la parte estacional de la misma, dado que lo rezagos estacionales en la FACM observada en la @fig-serie5 parecen decrecer lentamente de forma lineal, pasando a trabajar con 62 observaciones. 

```{r diferenciacion de la serie}
diferencia_est <- difference(datos_entrenamiento$ln_y, differences = 12)
datos_diferencia <- datos_entrenamiento
datos_diferencia$dif_est <- diferencia_est
```

```{r fac dif est}
autocorrelacion_dif <- acf(datos_diferencia$dif_est[13:74], lag.max = 61, plot = F)
datos_autocorrelacion_dif <- data.frame(
  acf = autocorrelacion_dif$acf,
  lag = autocorrelacion_dif$lag
)

alpha <- 0.95
conf.lims <- c(-1,1)*qnorm((1 + alpha)/2)/sqrt(autocorrelacion_dif$n.used)
```

```{r facp dif est}
pautocorrelacion_dif <- pacf(datos_diferencia$dif_est[13:74], lag.max = 61, plot = F)
datos_pautocorrelacion_dif <- data.frame(
  pacf = pautocorrelacion_dif$acf,
  lag = pautocorrelacion_dif$lag
)

alpha <- 0.95
conf.lims <- c(-1,1)*qnorm((1 + alpha)/2)/sqrt(pautocorrelacion_dif$n.used)
```

\newpage

```{r graficos de la serie diferenciada}
#| label: fig-serie6
#| layout: [[50], [50, 50]]
#| fig-cap: "Resumen de la Serie diferenciada en la parte estacional"
#| fig-subcap: 
#|   - "Log. natural de las unidades vendidas mensuales en (HL)"
#|   - "FACM"
#|   - "FACPM"

datos_diferencia[13:74,] |>  
  ggplot() +
  aes(x = `Año/Mes`, y = dif_est) +
  geom_line() +
  geom_point(size = 1.5, color = "dodgerblue2") +
  scale_x_date(breaks = scales::date_breaks("1 year"), labels = scales::date_format("%Y")) +
  labs(x = "Fecha", y = "Log. natural de la cantidad total vendida (HL)") +
  theme_bw()

datos_autocorrelacion_dif |> 
  ggplot() +
  aes(x = lag, y = acf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = acf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(x = "Rezago", y = expression(rho[k])) +
  theme_bw()

datos_pautocorrelacion_dif |> 
  ggplot() +
  aes(x = lag, y = pacf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = pacf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(x = "Rezago", y = expression(Phi[kk])) +
  theme_bw()
```

Se visualiza en la @fig-serie6, el gráfico de la serie diferenciada en la parte estacional y sus respectivas funciones de autocorrelación muestral y de autocorrelación parcial muestral. En la Figura (6a) se puede observar que la serie parece ser estacionaria en media, dado que varía de manera oscilante sobre un valor constante. 
Luego para realizar la identificación de los posibles modelos que se pueden ajustar a esta serie, se utilizan las Figuras (6b) y (6c). En el gráfico de la FACM se puede observar en la parte regular qué, los dos primeros rezagos son significativos y el tercero está al límite de ser significativo, viendo la parte estacional parece que los rezagos 12, 24 y 36 son significativos, presentando un decrecimiento exponencial. En el gráfico de la FACPM se puede observar que solo los primeros 2 rezagos son significativos, y el rezago 12 correspondiente a la parte estacional, parece estar al límite de ser significativo.

\newpage

Por lo que teniendo esto en cuenta, se plantea los siguientes modelos que se pueden ajustar a nuestra serie: 

- Modelo 1: $SARIMA(0,0,3)(1,1,0)_{12}$
- Modelo 2: $SARIMA(0,0,2)(1,1,0)_{12}$
- Modelo 3: $SARIMA(2,0,0)(1,1,0)_{12}$
- Modelo 4: $SARIMA(1,0,0)(0,1,1)_{12}$, selección del modelo de forma automática 

```{r tsibble}
datos_diferencia_2 <- datos_diferencia |> 
  mutate(mes = as.numeric(mes),
         date = yearmonth(`Año/Mes`),
         key = 1) |> 
  dplyr::select(-`Año/Mes`) |> 
  as_tsibble(key = key,
             index = date,
             validate = T,
             regular = T)
```

Una vez planteado los modelos que vamos a utilizar para el pronóstico de la serie, se procede a estimarlos y compararlos.

```{r ajustes de modelo con la variable transformada}
#| tbl-cap: "Comparación de los modelos"

ajustes2 <- datos_diferencia_2 |>
  model(
    auto = ARIMA(log(Cantidad_total_HL), stepwise = F, approximation = F, method = "ML"),
    sarima003110 = ARIMA(log(Cantidad_total_HL) ~ pdq(0,0,3) + PDQ(1,1,0), method = "ML"),
    sarima002110 = ARIMA(log(Cantidad_total_HL) ~ pdq(0,0,2) + PDQ(1,1,0), method = "ML"),
    sarima200110 = ARIMA(log(Cantidad_total_HL) ~ pdq(2,0,0) + PDQ(1,1,0), method = "ML"),
    sarima100110 = ARIMA(log(Cantidad_total_HL) ~ pdq(1,0,0) + PDQ(1,1,0), method = "ML")
  )
# ajustes2 |>
#   dplyr::select(-key) |>
#   tidyr::pivot_longer(everything(), names_to = "Modelos",
#                      values_to = "Orden")
glance(ajustes2 |> dplyr::select(-key, -'sarima100110')) |> 
  arrange(AICc) |> 
  dplyr::select(.model:BIC) |>
  mutate(nombre_modelos = c("$SARIMA(1,0,0)(0,1,1)_{12}$", "$SARIMA(2,0,0)(1,1,0)_{12}$", "$SARIMA(0,0,2)(1,1,0)_{12}$", "$SARIMA(0,0,3)(1,1,0)_{12}$")) |>
  relocate(nombre_modelos) |> 
  dplyr::select(-.model) |> 
  `colnames<-`(c("Modelos", "$\\hat\\sigma^2$", "Log_veros.","AIC", "AICc", "BIC")) |> 
  kable(digits = 4)
```

```{r estimacion con arima}
m_auto_2 <- arima(datos_diferencia_2$ln_y, order = c(1,0,0), seasonal = list(order = c(0,1,1), period = 12), method = "ML")


# m_auto_2 # Los dos parámetros son significativos

m_prop_2 <- arima(datos_diferencia_2$ln_y, order = c(2,0,0), seasonal = list(order = c(1,1,0), period = 12), method = "ML")

# m_prop_2 # ar1 y sar1 son significativos, ar2 no es significativo

m_prop_2.1 <- arima(datos_diferencia_2$ln_y, order = c(1,0,0), seasonal = list(order = c(1,1,0), period = 12), method = "ML")
```

Se puede observar, que los modelos con menor $AIC$ son:

- Modelo 3 $SARIMA(2,0,0)(1,1,0)_{12}$
- Modelo 4 $SARIMA(1,0,0)(0,1,1)_{12}$

El modelo 3 tiene 3 parámetros de los cuáles $\phi_2$ no es significativo, se puede observar esto en la tabla 4 del anexo. Por esta razón, se elimina un parámetro en la parte regular del modelo. Así, el Modelo 3 se reemplaza por un modelo $SARIMA(1,0,0)(1,1,0)_{12}$. Con respecto al modelo 4, sus dos parámetros son significativos, teniendo además una estimación de $\hat\sigma^2$ menor que la del modelo 3. Del mismo modo, se analizan ambos modelos para determinar cuál utilizar en las predicciones, seleccionando el que ofrezca una mejor capacidad predictiva, con base en la verificación de sus supuestos.

## Evaluación de los supuestos de los modelos

Esta instancia se centra en la verificación de los supuestos de ambos modelos mencionados anteriormente. Se hará un análisis exhaustivo para el modelo $SARIMA(1,0,0)(0,1,1)_{12}$, mientras que para el modelo $SARIMA(1,0,0)(1,1,0)_{12}$, al ser un procedimiento análogo, se dejarán en el anexo, en la @fig-serie-anexo.

```{r chequeo de los supuestos}
m_propuesto <- augment(ajustes2) |>
  filter(.model == "sarima100110")

m_auto <- augment(ajustes2) |>
  filter(.model == "auto")
```

```{r data frame para los graficos}
acf_auto <- acf(m_auto$.innov, lag.max = 61, plot = F)
pacf_auto <- pacf(m_auto$.innov, lag.max = 61, plot = F)

datos_autocorrelacion_auto <- data.frame(
  lag = acf_auto$lag,
  acf = acf_auto$acf
)

datos_pautocorrelacion_auto <- data.frame(
  lag = pacf_auto$lag,
  pacf = pacf_auto$acf
)
```

\newpage 

```{r residuos auto graficos}
#| label: fig-serie7
#| layout: [[49, -2 ,49], [49, -2 ,49]]
#| fig-cap: "Análisis de residuos $SARIMA(1,0,0)(0,1,1)_{12}$"
#| fig-subcap: 
#|   - "Residuos estandarizados vs fecha"
#|   - "Histograma de los residuos estandarizados"
#|   - "FACM de los residuos"
#|   - "FACPM de los residuos"

m_auto |> 
  mutate(innov_est = .innov/sd(.innov)) |> 
  ggplot() +
  aes(x = datos_diferencia$`Año/Mes`, y = innov_est) +
  geom_line() +
  geom_hline(yintercept = c(-3, 3), linetype = "dashed", col = "blue") +
  geom_point(size = 1.5, color = "dodgerblue2") +
  scale_x_date(breaks = scales::date_breaks("1 year"), labels = scales::date_format("%Y")) +
  labs(x = "Fecha", y = "Residuos estandarizados") +
  theme_bw() # Hay un outlier

m_auto |> 
  mutate(innov_est = .innov/sd(.innov)) |> 
  ggplot() +
  aes(x = innov_est) +
  geom_histogram(aes(x = innov_est, y = ..density..), fill = "dodgerblue2", color = "black", bins = 12) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), size = 1) +
  labs(x = "Residuos estandarizados", y = "Densidad") +
  theme_bw()

datos_autocorrelacion_auto |>
  filter(lag != 0) |> 
  ggplot() +
  aes(x = lag, y = acf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = acf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(x = "Rezago", y = expression(rho[k])) +
  theme_bw()

datos_pautocorrelacion_auto |> 
  ggplot() +
  aes(x = lag, y = pacf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = pacf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(x = "Rezago", y = expression(Phi[kk])) +
  theme_bw()

```

En la parte (a) y (b) de la @fig-serie7 se puede observar que hay una observación atípica, correspondiente al año 2020, lo cual se puede deber a alguna situación inusual ocurrida en pandemia, además los residuos varían alrededor del cero y parecen tener una variancia constante. También se puede apreciar, en la Figura (7b) que los residuos parecen ser normales, obviamente sin incluir al outlier. Luego en las Figuras (7c) y (7d), da la impresión de que los residuos son incorrelados, en la tabla 5 que se encuentra en el anexo, se incluye el test de Ljung-Box para comprobar que los residuos son incorrelados. Por lo que se puede concluir que el modelo $SARIMA(1,0,0)(0,1,1)_{12}$ cumple con los supuestos teóricos.

Para el modelo $SARIMA(1,0,0)(1,1,0)_{12}$ se realizó lo mismo obteniendo resultados análogos al modelo anterior, esto se puede observar en la @fig-serie-anexo.

## Evaluación de la capacidad predictiva

Dado que los dos modelos mencionados anteriormente satisfacen los supuestos teóricos, la manera de decidir cuál utilizar para realizar las predicciones es en base a la capacidad predictiva que tienen, es decir, nos quedaremos con aquel modelo que tenga menor error de predicción. Para ello haremos uso de varias métricas, haciendo especial énfasis sobre el *MAPE*, dado que es expresado como un porcentaje lo cual facilita las interpretaciones y las comparaciones.


```{r comparación de la capacidad predictiva 1}
#| tbl-cap: "Evaluación de la capacidad predictiva"

# Convertimos el data set a objeto series de tiempo
datos_prueba_2 <- datos_prueba |> 
  mutate(mes = as.numeric(mes),
         date = yearmonth(`Año/Mes`),
         key = 1) |> 
  dplyr::select(-`Año/Mes`) |> 
  as_tsibble(key = key,
             index = date,
             validate = T,
             regular = T)

# Comparación de la capacidada predictiva
forecast(ajustes2, h=6) |>
  filter(.model %in% c('auto', 'sarima100110')) |>
  accuracy(datos_prueba_2) |>
  dplyr::select(.model, RMSE:MAPE, -MPE) |> 
  mutate(nombre_modelos = c("$SARIMA(1,0,0)(0,1,1)_{12}$", "$SARIMA(1,0,0)(1,1,0)_{12}$")) |>
  relocate(nombre_modelos) |> 
  dplyr::select(-.model) |> 
  `colnames<-`(c("Modelos", "RMSE", "MAE", "MAPE")) |> 
  kable(digits = 4)
```

En la tabla 3, se puede verificar que el modelo $SARIMA(1,0,0)(0,1,1)_{12}$ tiene todas las medidas de error de pronóstico más bajas, por lo cual, dicho modelo se utilizará para realizar las predicciones.

```{r data frame con los datos de la predicción}
# Predicciones
predicciones <- forecast(ajustes2, h=6) |>
  filter(.model == 'auto')

# Data frame con las predicciones
datos_prueba_2 <- datos_prueba_2 |> 
  mutate(estimacion_puntual = predicciones$.mean,
         distribucion = predicciones$Cantidad_total_HL)
```

```{r gráfico de las predicciones con el modelo auto}
#| label: fig-serie8
#| layout-nrow: 2
#| fig-cap: "Comparación del pronóstico vs el valor real"
#| fig-subcap:
#|   - "Pronósticos de las unidades vendidas en (HL) desde 03/2024 - 08/2024"
#|   - "Pronósticos de las unidades vendidas en (HL) desde 03/2024 - 08/2024 vs unidades vendidas en (HL) reales"
#| fig-height: 2.80
#| fig-width: 4

predicciones |> 
  autoplot(datos_diferencia_2 |> 
             mutate(date = yearmonth(date)),
           size = 1, colour = "dodgerblue2") +
  scale_y_continuous(breaks = seq(6000, 20000, 2000)) +
  guides(fill_ramp = guide_legend(title = "Intervalo de predicción")) +
  labs(x = "Fecha", 
       y = "Cantidad total vendida (HL)") +
  theme_bw() +
  theme(legend.position = "bottom")


predicciones |> 
  autoplot(datos_prueba_2, colour = "dodgerblue2", size = 1) +
  scale_y_continuous(breaks = seq(6000, 20000, 1000)) +
  guides(fill_ramp = guide_legend(title = "Intervalo de predicción")) +
  labs(x = "Fecha", 
       y = "Cantidad total vendida (HL)") +
  theme_bw() +
  theme(legend.position = "bottom")
```

\newpage

En la @fig-serie8 se pueden observar las predicciones realizadas utilizando el modelo seleccionado anteriormente, en la Figura (8b) se puede ver una comparación entre el valor real (línea negra) y las predicciones realizadas (línea azul), observando que los valores reales en su mayoría se encuentran dentro del intervalo de predicción. Lo que sucede en agosto es que la empresa a la que se le analizaron los datos tuvo una decaída en las ventas sujeto a un problema en las bonificaciones por falta de presupuesto.

## Conclusión

El análisis de las ventas mensuales reveló un comportamiento estacional sin tendencias a través de los años, el cual no tiene mayores inconvenientes además de que la variancia no es constante en el tiempo y el outlier encontrado en el año 2020, sujeto al escenario atípico que se vivió en dicho año. En base a esto, se ajustó un modelo SARIMA no muy complicado con una diferencia en la parte estacional, una parte autorregresiva de primer orden en la parte regular y una parte promedio móvil de primer orden en la parte estacional, el cuál satisface todos los supuestos teóricos.

Luego, en la parte de los resultados se vio que el modelo ajustado tenía un *MAPE* del 14.4% aproximadamente, lo cual significa que el error promedio de los pronósticos se desvían un 14.4% respecto a las unidades vendidas reales, algo que es aceptable pero lo ideal sería un error más pequeño. 

Por último, es fundamental tener en cuenta el pronóstico para agosto de 2024, dado que durante ese mes surgió un problema con las bonificaciones en la empresa debido a la falta de presupuesto. Este factor podría haber afectado el desempeño del modelo, lo que sugiere que el error estimado podría ser menor que el observado.


\newpage

## Anexo

Todo el código con el cuál se desarrolló el trabajo práctico se encuentra en mi repositorio de Github, al cual se puede acceder haciendo [click aquí](https://github.com/Franco-Santini/TP_series).

```{r data frame para las estimaciones}
data_estimaciones1 <- data.frame(
  parametros = c("$\\phi_1$", "$\\phi_2$", "$\\Phi_1$"),
  estimacion = c(m_prop_2$coef),
  desvio = c(sqrt(diag(m_prop_2$var.coef))),
  estadistica = c((m_prop_2$coef/sqrt(diag(m_prop_2$var.coef)))^2)
) |> 
  mutate(p.value = ifelse(pchisq(estadistica, df = 1, lower.tail = F) < 0.0001, "<0.0001", round(pchisq(estadistica, df = 1, lower.tail = F), 5)))

data_estimaciones2 <- data.frame(
  parametros = c("$\\phi_1$", "$\\Phi_1$"),
  estimacion = c(m_prop_2.1$coef),
  desvio = c(sqrt(diag(m_prop_2.1$var.coef))),
  estadistica = c((m_prop_2.1$coef/sqrt(diag(m_prop_2.1$var.coef)))^2)
) |> 
  mutate(p.value = ifelse(pchisq(estadistica, df = 1, lower.tail = F) < 0.0001, "<0.0001", round(pchisq(estadistica, df = 1, lower.tail = F), 5)))

data_estimaciones3 <- data.frame(
  parametros = c("$\\phi_1$", "$\\Theta_1$"),
  estimacion = c(m_auto_2$coef),
  desvio = c(sqrt(diag(m_auto_2$var.coef))),
  estadistica = c((m_auto_2$coef/sqrt(diag(m_auto_2$var.coef)))^2)
) |> 
  mutate(p.value = ifelse(pchisq(estadistica, df = 1, lower.tail = F) < 0.0001, "<0.0001", round(pchisq(estadistica, df = 1, lower.tail = F), 5)))
```


```{r tabla estimaciones de los parámetros}
#| tbl-cap: "Estimación de los parámetros y su significación estadística"
#| tbl-subcap: 
#|   - "Modelo $SARIMA(2,0,0)(1,1,0)_{12}$"
#|   - "Modelo $SARIMA(1,0,0)(1,1,0)_{12}$"
#|   - "Modelo $SARIMA(1,0,0)(0,1,1)_{12}$"
#| layout-nrow: 3


data_estimaciones1 |>
  `rownames<-`(NULL) |> 
  `colnames<-`(c("Parámetro", "Estimación", "Desvío", "Estadística", "P-Value")) |> 
  kable(digits = 4)

data_estimaciones2 |>
  `rownames<-`(NULL) |> 
  `colnames<-`(c("Parámetro", "Estimación", "Desvío", "Estadística", "P-Value")) |> 
  kable(digits = 4)

data_estimaciones3 |>
  `rownames<-`(NULL) |> 
  `colnames<-`(c("Parámetro", "Estimación", "Desvío", "Estadística", "P-Value")) |> 
  kable(digits = 4)
```


```{r data frame para los graficos 2}
acf_prop <- acf(m_propuesto$.innov, lag.max = 61, plot = F)
pacf_prop <- pacf(m_propuesto$.innov, lag.max = 61, plot = F)

datos_autocorrelacion_prop <- data.frame(
  lag = acf_prop$lag,
  acf = acf_prop$acf
)

datos_pautocorrelacion_prop <- data.frame(
  lag = pacf_prop$lag,
  pacf = pacf_prop$acf
)
```

```{r ljung-box test 1}
# Tabla cada 6 rezagos
ljung_box_auto <- data.frame(
  rezago = c(6, 12, 18, 24, 30, 36),
  estadistica = c(ljung_box(m_auto$.innov, lag = 6, dof = 2)[1],
           ljung_box(m_auto$.innov, lag = 12, dof = 2)[1],
           ljung_box(m_auto$.innov, lag = 18, dof = 2)[1],
           ljung_box(m_auto$.innov, lag = 24, dof = 2)[1],
           ljung_box(m_auto$.innov, lag = 30, dof = 2)[1],
           ljung_box(m_auto$.innov, lag = 36, dof = 2)[1]),
  grados_libertad = c(6-2, 12-2, 18-2, 24-2, 30-2, 36-2),
  test = c(ljung_box(m_auto$.innov, lag = 6, dof = 2)[2],
           ljung_box(m_auto$.innov, lag = 12, dof = 2)[2],
           ljung_box(m_auto$.innov, lag = 18, dof = 2)[2],
           ljung_box(m_auto$.innov, lag = 24, dof = 2)[2],
           ljung_box(m_auto$.innov, lag = 30, dof = 2)[2],
           ljung_box(m_auto$.innov, lag = 36, dof = 2)[2])
)

ljung_box_prop <- data.frame(
  rezago = c(6, 12, 18, 24, 30, 36),
  estadistica = c(ljung_box(m_propuesto$.innov, lag = 6, dof = 2, fit_df = 2)[1],
           ljung_box(m_propuesto$.innov, lag = 12, dof = 2, fit_df = 2)[1],
           ljung_box(m_propuesto$.innov, lag = 18, dof = 2, fit_df = 2)[1],
           ljung_box(m_propuesto$.innov, lag = 24, dof = 2, fit_df = 2)[1],
           ljung_box(m_propuesto$.innov, lag = 30, dof = 2, fit_df = 2)[1],
           ljung_box(m_propuesto$.innov, lag = 36, dof = 2, fit_df = 2)[1]),
  grados_libertad = c(6-2, 12-2, 18-2, 24-2, 30-2, 36-2),
  test = c(ljung_box(m_propuesto$.innov, lag = 6, dof = 2, fit_df = 2)[2],
           ljung_box(m_propuesto$.innov, lag = 12, dof = 2, fit_df = 2)[2],
           ljung_box(m_propuesto$.innov, lag = 18, dof = 2, fit_df = 2)[2],
           ljung_box(m_propuesto$.innov, lag = 24, dof = 2, fit_df = 2)[2],
           ljung_box(m_propuesto$.innov, lag = 30, dof = 2, fit_df = 2)[2],
           ljung_box(m_propuesto$.innov, lag = 36, dof = 2, fit_df = 2)[2])
)
```

```{r test ljung-box 1}
#| tbl-cap: "Test de Ljung-Box cada 6 rezagos"
#| tbl-subcap: 
#|   - "Modelo $SARIMA(1,0,0)(0,1,1)_{12}$"
#|   - "Modelo $SARIMA(1,0,0)(1,1,0)_{12}$"
#| layout-ncol: 2

ljung_box_auto |> 
    `colnames<-`(c("Rezago", "Estadística", "G.L", "P-value")) |> 
    kable(digits = 4)

ljung_box_prop |> 
    `colnames<-`(c("Rezago", "Estadística", "G.L", "P-value")) |> 
    kable(digits = 4)
```

\newpage 

```{r residuos auto graficos 2}
#| label: fig-serie-anexo
#| layout: [[49, -2 ,49], [49, -2 ,49]]
#| fig-cap: "Análisis de residuos $SARIMA(1,0,0)(1,1,0)_{12}$"
#| fig-subcap: 
#|   - "Residuos estandarizados vs fecha"
#|   - "Histograma de los residuos estandarizados"
#|   - "FACM de los residuos"
#|   - "FACPM de los residuos"

m_propuesto |> 
  mutate(innov_est = .innov/sd(.innov)) |> 
  ggplot() +
  aes(x = datos_diferencia$`Año/Mes`, y = innov_est) +
  geom_line() +
  geom_hline(yintercept = c(-3, 3), linetype = "dashed", col = "blue") +
  geom_point(size = 1.5, color = "dodgerblue2") +
  scale_x_date(breaks = scales::date_breaks("1 year"), labels = scales::date_format("%Y")) +
  labs(x = "Fecha", y = "Residuos estandarizados") +
  theme_bw() # Hay un outlier

m_propuesto |> 
  mutate(innov_est = .innov/sd(.innov)) |> 
  ggplot() +
  aes(x = innov_est) +
  geom_histogram(aes(x = innov_est, y = ..density..), fill = "dodgerblue2", color = "black", bins = 12) +
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), size = 1) +
  labs(x = "Residuos estandarizados", y = "Densidad") +
  theme_bw()

datos_autocorrelacion_prop |>
  filter(lag != 0) |> 
  ggplot() +
  aes(x = lag, y = acf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = acf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(x = "Rezago", y = expression(rho[k])) +
  theme_bw()

datos_pautocorrelacion_prop |> 
  ggplot() +
  aes(x = lag, y = pacf) +
  geom_segment(aes(x = lag, xend = lag, y = 0, yend = pacf), linewidth = 1) +
  geom_point(size = 1.5, color = "dodgerblue2") +
  geom_hline(yintercept=conf.lims, lty=2, col='blue') +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = seq(0, 80, 4)) +
  labs(x = "Rezago", y = expression(Phi[kk])) +
  theme_bw()

```


\newpage

## Bibliografía

- Wei, W. S. (2006). *Time series analysis: Univariate and multivariate methods* (2nd ed.). Addison-Wesley.

- Hyndman, R. J., & Athanasopoulos, G. (2021). *Forecasting: Principles and practice* (3rd ed.). OTexts.

- Guerrero, V. M. (1993). Time-series analysis supported by power transformations. *Journal of Forecasting, 12*(1), 37–48.
